# CLMMU/CEVAL 数据集筛选工具 README

## 一、工具简介
本工具是一款针对 CLMMU/CEVAL 等学术数据集的高效筛选工具，支持 **数据去重、敏感内容过滤、口语化过滤、学术特征筛选、分层困惑度质量评估** 等核心功能，可快速筛选出高质量、低冗余的学术数据，适用于大模型训练/微调场景。

核心特性：
- 模块化设计：5个文件各司其职，配置与逻辑分离，易维护
- 双重去重：MD5 精确去重+MinHash LSH语义去重
- 多维度过滤：敏感话题、口语化、非学术内容、长度异常过滤
- 分层质量评估：现代文（低困惑度=高质量）+ 古文（高困惑度=真实）
- 灵活模式：支持抽样快速验证 + 全量数据处理

## 二、目录结构
```
project/
├── config.py                   # 所有配置项（核心！修改参数必看）
├── utils.py                    # 通用工具函数（无需修改）
├── deduplication.py            # 去重模块（无需修改）
├── filtering.py                # 筛选模块（无需修改）
├── main.py                     # 主程序入口（运行入口）
├── data/                       # 数据目录（需手动创建或调整路径）
│   ├── part_0000x.jsonl        # 输入JSONL文件（用户需放置数据）
│   ├── intermediate/           # 中间文件（自动生成，无需干预）
│   └── output/                 # 输出结果（自动生成）
└── requirements.txt            # 依赖包清单
```

## 三、环境配置
### 1. 依赖安装
首先安装 Python 3.8+（推荐 3.9-3.11），然后执行以下命令安装依赖：
```bash
# 方式1：直接安装
pip install torch transformers tqdm datasketch psutil numpy matplotlib

# 方式2：使用requirements.txt（推荐）
# 先创建 requirements.txt 文件，复制下方内容，再执行安装命令
pip install -r requirements.txt
```

`requirements.txt` 内容：
```txt
torch>=1.17.0
transformers>=4.40.0
tqdm>=4.66.0
datasketch>=1.5.9
psutil>=5.9.8
numpy>=1.26.0
matplotlib>=3.8.0
```

### 2. 显卡要求
- 推荐使用 GPU（CUDA 11.8+），计算困惑度时速度提升 10-20 倍
- 无 GPU 时自动使用 CPU，但处理大文件会较慢
- 单卡显存建议 ≥8GB（批量处理时避免内存溢出）

## 四、使用步骤
### 1. 准备输入数据
- 数据格式：**JSONL**（每行一个 JSON 对象）
- 必须字段：`text`（待筛选的文本内容），其他字段保留原样
- 数据路径：默认放置在 `data/input/` 目录下（可在 `config.py` 中修改路径）

示例输入（`data/input/sample.jsonl`）：
```json
{"text": "本文提出一种基于深度学习的图像分割方法，通过实验验证了模型的有效性", "author": "xxx", "year": 2024}
{"text": "卧槽，这个模型也太牛逼了吧！666", "source": "网络"}
{"text": "论语曰：学而时习之，不亦说乎？有朋自远方来，不亦乐乎？", "book": "论语"}
```

### 2. 核心配置（重点！决定运行模式）
所有配置都在 `config.py` 中修改，无需改动其他文件。以下是高频配置项：

| 配置项                | 作用                          | 抽样模式（默认） | 全量模式建议       |
|-----------------------|-------------------------------|------------------|--------------------|
| `INPUT_DIR`           | 输入数据目录                   | "data/input"     | 按需修改（如 "/data/clmmu"） |
| `SAMPLING_ENABLE`     | 是否启用抽样                   | True（抽样）     | False（全量）      |
| `SAMPLE_RATIO`        | 抽样比例（0-1）               | 0.01（抽1%）     | -（无需设置）      |
| `MAX_SAMPLE_COUNT`    | 最大抽样数量                  | 10000（最多1万条）| -（无需设置）      |
| `MIN_CHAR_LEN`        | 文本最小长度（过滤过短内容）  | 8                | 8-16（按需调整）   |
| `MAX_CHAR_LEN`        | 文本最大长度（过滤过长内容）  | 12000            | 12000-20000        |
| `LSH_THRESHOLD`       | 语义去重阈值（0-1）           | 0.76（中等严格） | 0.78（更严格）/0.73（宽松） |
| `ACADEMIC_REQUIRE`    | 是否强制要求学术特征          | False（可选）    | True（确保学术性） |

### 3. 运行代码
在项目根目录执行以下命令，直接启动筛选流程：
```bash
python main.py
```

### 4. 查看输出结果
运行完成后，所有结果保存在 `data/output/` 目录下：
| 输出文件                     | 作用                          
|------------------------------|-------------------------------|
 `clmmu_kept_data_final.jsonl` | 最终筛选后的高质量数据（核心输出） 
 `clmmu_classic_chinese_data_final.jsonl` | 单独提取的古文数据 
 `clmmu_filtered_data_final.jsonl` | 被过滤的数据（含过滤原因） 
 `clmmu_filter_log_final.log` | 完整运行日志（排障用）
 `layered_perplexity_distribution_final.png` | 困惑度分布图（可视化质量分布） 


## 五、关键模式切换说明
### 1. 抽样模式（默认，快速验证）
#### 用途：
快速测试配置是否合理、筛选效果是否符合预期（无需等待全量处理）。

#### 配置方式：
```python
# config.py 中保持以下配置
SAMPLING_ENABLE = True  # 启用抽样
SAMPLE_RATIO = 0.01     # 抽取 1% 的数据（可调整为 0.05=5%）
MAX_SAMPLE_COUNT = 10000  # 最多抽 1 万条（避免样本过多）
```

#### 注意事项：
- 抽样是随机的，结果仅作参考，最终筛选请用全量模式
- 若输入数据量小于 `MAX_SAMPLE_COUNT`，则抽取全部数据

### 2. 全量模式（最终筛选）
#### 用途：处理完整数据集，生成最终可用数据。

#### 配置方式：
```python
# config.py 中修改以下配置
SAMPLING_ENABLE = False  # 禁用抽样（关键！）
# 以下两个参数无需修改，禁用抽样后自动失效
SAMPLE_RATIO = 0.01      # 无效
MAX_SAMPLE_COUNT = 10000 # 无效
```

#### 注意事项：
- 全量处理前，建议先用抽样模式验证配置（避免因参数不当导致白忙活）
- 处理大文件（100万条+）时，建议：
  1. 增大 `BATCH_SIZE_PREPROCESS`（如 2048）提升速度
  2. 确保磁盘空间充足（中间文件+输出文件可能占用数GB）
  3. 开启 GPU 加速（否则耗时极长）
- 若数据量极大（1000万条+），可分批次处理（按文件拆分输入）

## 六、其他重要配置说明
### 1. 敏感话题过滤
默认过滤色情、暴力、毒品、政治敏感等内容，可在 `config.py` 中修改敏感词列表：
```python
# 敏感话题关键词（可新增/删除）
SENSITIVE_KEYWORDS = {
    "色情相关": ["色情", "裸聊", ...],
    "暴力相关": ["杀人", "抢劫", ...],
    # 新增其他敏感类别
}
```

### 2. 口语化过滤
默认过滤含网络流行语、口语化表达的内容，可补充口语关键词：
```python
# 口语关键词列表（可新增如 "绝绝子"、"谁懂啊" 等）
COLLOQUIAL_WORDS = ["卧槽", "牛逼", "哈哈哈", ...]
```

### 3. 困惑度筛选（质量控制核心）
分层困惑度阈值是自动计算的（基于数据分布），但可调整分位数：
```python
MODERN_PERPLEXITY_PERCENTILE = 75  # 现代文取 75% 分位数（≤该值保留，越低质量越高）
CLASSIC_PERPLEXITY_PERCENTILE = 10  # 古文取 10% 分位数（≥该值保留，越高越真实）
PERPLEXITY_MAX_LIMIT = 15000  # 异常值过滤（超过该值直接过滤）
```

#### 调整建议：
- 若现代文保留过多低质量内容，降低 `MODERN_PERPLEXITY_PERCENTILE`（如 70）
- 若古文保留过少，降低 `CLASSIC_PERPLEXITY_PERCENTILE`（如 5）

### 4. 学术特征筛选
默认不强制要求学术特征（`ACADEMIC_REQUIRE = False`），若需仅保留学术类数据：
```python
ACADEMIC_REQUIRE = True  # 强制要求含学术特征（公式、定理、实验等）
```

学术特征模式可补充：
```python
ACADEMIC_PATTERNS = [r"定义[:：]", r"定理", r"实验", r"[A-Za-z0-9]=.*[A-Za-z0-9]"]  # 公式、学术术语
```

## 七、注意事项
### 1. 数据格式要求
- 必须是 JSONL 格式，每行一个 JSON 对象
- 必须包含 `text` 字段（否则会被过滤）
- 文本编码为 UTF-8（避免中文乱码）

### 2. 常见问题排查
- **找不到输入文件**：检查 `INPUT_DIR` 路径是否正确，确保目录下有 `.jsonl` 文件
- **模型加载失败**：确保 `transformers` 版本≥4.40.0，或更换模型（`MODEL_ID` 改为 "gpt2" 测试）
- **GPU 内存溢出**：减小 `BATCH_SIZE_PERPLEXITY`（如 16），或启用 CPU 模式
- **保留比例过低（<45%）**：放松筛选条件（降低 `LSH_THRESHOLD`、提高 `MODERN_PERPLEXITY_PERCENTILE`）
- **保留比例过高（>55%）**：收紧筛选条件（提高 `LSH_THRESHOLD`、降低 `MODERN_PERPLEXITY_PERCENTILE`）

### 3. 性能优化建议
- 开启 GPU 加速（核心！）
- 增大批量大小（`BATCH_SIZE_PREPROCESS`、`BATCH_SIZE_MINHASH`）
- 分批次处理超大文件
- 关闭 matplotlib 可视化（注释 `filtering.py` 中绘图代码，节省时间）

## 八、联系方式
若遇到问题或需要功能扩展，可通过以下方式反馈：
- 问题描述：请附上 `config.py` 配置、日志文件片段、输入数据示例
- 建议：欢迎提出优化建议或新增功能需求

---

## 总结
1. 首次使用：先配置抽样模式，验证筛选效果
2. 最终筛选：切换全量模式，生成高质量数据
3. 参数调整：所有配置集中在 `config.py`，无需修改核心代码
4. 排障：优先查看 `data/output/clmmu_filter_log_final.log` 日志文件

按照以上步骤操作，即可快速完成 CLMMU/CEVAL 数据集的筛选优化！